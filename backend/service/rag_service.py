"""
RAG (Retrieval-Augmented Generation) ì„œë¹„ìŠ¤
ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±
"""
from typing import List, Dict
from openai import AzureOpenAI
import os
from dotenv import load_dotenv

from backend.service.azure_search import AzureSearchService

load_dotenv()


class RAGService:
    """RAG ì„œë¹„ìŠ¤ - ê²€ìƒ‰ + ìƒì„±"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        
        # Search ì„œë¹„ìŠ¤
        self.search_service = AzureSearchService()
        
        print("âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            response = self.openai_client.embeddings.create(
                model=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return [0.0] * 1536  # ë”ë¯¸ ë²¡í„°
    
    def search_relevant_documents(
        self,
        query: str,
        top: int = 5
    ) -> List[Dict]:
        """
        ì¿¼ë¦¬ì— ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰
        """
        # ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_vector = self.get_embedding(query)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        documents = self.search_service.hybrid_search(
            query=query,
            query_vector=query_vector,
            top=top
        )
        
        return documents
    
    def generate_context_aware_summary(
        self,
        query: str,
        documents: List[Dict]
    ) -> str:
        """
        ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§¥ë½ ìš”ì•½ ìƒì„±
        """
        if not documents:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë³€ê²½í•´ë³´ì„¸ìš”."
        
        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "\n\n".join([
            f"[{doc['source']}] {doc['title']}\nì‘ì„±ì¼: {doc['date']}\në‚´ìš©: {doc['content'][:500]}"
            for doc in documents[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        ])
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = """ë‹¹ì‹ ì€ ì—…ë¬´ ë§¥ë½ì„ ë¶„ì„í•˜ëŠ” AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ í˜•ì‹:
## ğŸ“‹ ì—…ë¬´ ë§¥ë½ ë¶„ì„ ê²°ê³¼

### ğŸ¯ í•µì‹¬ ìš”ì•½
(í•œ ë¬¸ì¥ìœ¼ë¡œ ì—…ë¬´ì˜ ë³¸ì§ˆ ì„¤ëª…)

### ğŸ“– ë°°ê²½ ë° ëª©ì 
(ì™œ ì´ ì—…ë¬´ê°€ ìƒê²¼ëŠ”ì§€)

### ğŸ‘¥ ì£¼ìš” ì´í•´ê´€ê³„ì
(ê´€ë ¨ëœ ì‚¬ëŒë“¤ê³¼ ì—­í• )

### ğŸ“… ì¼ì • ë° ìš°ì„ ìˆœìœ„
(ë§ˆê°ì¼, ìš°ì„ ìˆœìœ„)

### ğŸ”‘ í•µì‹¬ ë‚´ìš©
(ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ì´ë‚˜ ì¤‘ìš” ì‚¬í•­)

### âš¡ í˜„ì¬ ì§„í–‰ ìƒí™©
(ì§„í–‰ ìƒíƒœ)

ê°„ê²°í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        user_prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {query}

ê´€ë ¨ ë¬¸ì„œ:
{context}

ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return "AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def generate_action_items(
        self,
        query: str,
        documents: List[Dict]
    ) -> List[str]:
        """ì•¡ì…˜ ì•„ì´í…œ ìƒì„±"""
        if not documents:
            return ["ê´€ë ¨ ë¬¸ì„œê°€ ì—†ì–´ ì•¡ì…˜ ì•„ì´í…œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
        
        context = "\n".join([
            f"[{doc['source']}] {doc['content'][:300]}"
            for doc in documents[:2]
        ])
        
        prompt = f"""
ë‹¤ìŒ ì—…ë¬´ ìƒí™©ì—ì„œ í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œì„ 4-5ê°œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ê´€ë ¨ ì •ë³´:
{context}

ê° í•­ëª©ì€ í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , "- "ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
                messages=[
                    {"role": "system", "content": "ì•¡ì…˜ ì•„ì´í…œì„ ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=400
            )
            
            items = response.choices[0].message.content.strip().split('\n')
            return [item.strip('- ').strip() for item in items if item.strip() and item.strip().startswith('-')]
            
        except Exception as e:
            print(f"âŒ ì•¡ì…˜ ì•„ì´í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return ["ì•¡ì…˜ ì•„ì´í…œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."]